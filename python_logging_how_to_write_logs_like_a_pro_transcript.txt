in this video I'm going to take a deep dive into Python's logging package now you might think logging I mean that's kind of boring should we really watch a video about that why is that important but in commercial software products vlogging is actually crucial because login allows to detect bugs sooner it allows to trace back easily when a problem occurs in your platform so you can better help your customers and it also helps you detect and deal with for example hacking attempts but in order to do all these things you need to make sure that logging is set up correctly so that you can actually benefit from it the most so today I'll talk about how to do that in Python using Python's login module as well as a couple of things that are dealing with logs easier especially in a production environment and finally I'm going to talk about one huge mistake with logging that many companies make but fortunately you can do something to avoid it next to the logging helping you finding bugs and problems in your code it's also really good to develop your skill of diagnosing code in general so I created a free workshop on code diagnosis that you can access via Prime book called slash diagnosis it's about half an hour of content where I dive into a three Factor framework to help you analyze code more effectively I'll show you how to apply that framework by looking at actual production code so Arnold codes diagnosis to get access for free I've also put the link in the description of this video now let's dive in so I'm going to start by just showing you a very basic example of logging in Python I'm importing the login package here as you see I have main function that does nothing but logging that's normally not what you have of course but this just shows the basic capabilities of the package what I'm doing here in the first step is supplying a very basic configuration of logging by in this case simply supplying the level which is the warning level and then I post a number of different log messages a debug message info warning an error and a critical message and what this level does is that it determines which level of logging you want to print so when I run this you see that I'm printing warning error and critical but the debug and info messages are not shown now if I also want to show for example info messages I change this to info and I want to run this again you see we get also the info logging message or if I really want to go low level and also show debug then I run this and then I also show the debug messages so these are the five levels of severity of logging debug info warning error and critical being able to control up until what level you want to print logs is actually really helpful because then throughout your application you can use these severity levels to print things and you only have one place where you're defining how detailed the logs should be and you don't have to go through your code and enable and disable log messages just because you don't want to show them you simply Define in your basic config which severity level you want to see just the critical errors or do you want to basically see everything including low level debugging messages you can even imagine that this level is something that you might want to be able to set from let's say a database so that even when your application is already deployed you can in principle change the database logging level and then that's going to change the way that your application logging happens so basic config has other arguments as well for example you can set the file name if you want to write logs to a file or you can change the way that logging is formatted and I'll show you an example of that here I have a slightly modified version of the example that adds some formatting to logging so in this case what I'm doing is that I format it according to the time and the name of the level and then the message and it also provide a string formatting how date and time should look like in these log messages so before we simply add this we had the level and root which is the root logging application and the message but now when I run this with formatting it's going to look slightly differently so you see we have the date and the time here we have the level and there is a space between each of these things and then we get the actual message so this type of formatting is really helpful really easy to change and then you change it again in one place and then it's applied everywhere throughout your application code default login writes the logs to the console but you might also want to write a to file and you can simply do that by adding a file name argument in this case basic.box so when I run this we see that we don't get basic console logs anymore but if I open the file browser you see that there's now basic DOT log file that contains the logs that were generated and logging adds to the existing log file so if I run the log again then you see that base.log now contains these logs twice so this is a great way to keep track of what happened in earlier runs of your application it's really easy to set up by the way if you're enjoying this video so far give the like it really helps other people find my content on YouTube now simply writing a log to console or file is fine but if you're developing more complex application you generally want to have more control over how logging happens and it can be helpful to use a logging surface what log surfaces do is that they give you an easier way to visualize logs search logs have overall more control over how long logs are being saved and backups and things like that and they also are helpful sometimes if you want to give somebody else in your team maybe somebody is not a developer access to the logs because that might sometimes be useful there are several companies that offer logging surfaces I'm going to show you one of them today that's paper trail they're not sponsoring this video or anything I simply use them in the past and I thought it might be nice to just give you an example of what that looks like it's actually really easy to integrate in Python here I have a very simple setup of how that works so the only thing you need to do is you supply a host and a port that basically tells the logging system where to send the logs to by the way by the time you're watching this video this account no longer exists still sending logs to this account really doesn't do anything but you have your main function where I now use the logging module to create a locker object and that's basically what you're seeing here so in my previous example I simply used login.basic config but what I'm doing here is that I have a logger object and then I can also give that a name so you can have different logger objects for different parts of your application for example you could make one for your backhand you could make another one for your front end or you could even split it up more if you wanted to and the name of the application can also be mentioned in your log so you can easily find back where each log message came from very similar like we did with basic config your logger also has things like setting a logging level and in order to be able to send logs to a surface like paper trail well you need to add a Handler and that's what I'm doing here the basic Handler you can use for this is the syslog Handler that gets an address that is the host on the board and then we simply add this Handler to the logger and you can add multiple handlers so if you want to have the log being sent to Paper Trail but you also want it saved to a file you simply add a file Handler here and then we send a debug message so let me run this and now it has sent the login message to the logging surface so normally these login Services they give you access to web-based interface where you can browse search these logs for paper trail this is basically what it looks like and we see our login message right here that's the model logo matches as well I was trying out a few things but here you see our debug message and you also see that this comes from the logger and what's nice is that paper trail basically stores the logs for you keeps them available for a number of days so you can still browse them for a while if you want to look for a problem and they offer some possibilities to search for logs for example if I search for debug then I'm simply going to find this message that was sent a few minutes ago so that's really helpful and they have a couple of other things like there's charts that show you things like how many logs are being generated you have a couple of different settings about what you want to show or hide you can store favorite searches so you can quickly find things like I want to see quickly all the authentication errors or all the field login attempts or whatever so for those kind of things having a logging service like paper trail is really helpful and then of course you can give access to other members of your team to Paper Trail so they can easily see what's going on in the system without having to actually log into your server if you have any thoughts about logging services like paper trail or you have some experience with them just post it in a comment and let me know if you have any tips there's one big mistake that companies make when they're dealing with logs and that is that they often forget that they're logging things and as a result logs are actually a common reason for data leaks for example Twitter had data league in 2018 due to unhashed passwords being stored in a log file or the Cam4 streaming site they locked events in elastic search and basically the database was openly accessible and included email addresses Etc so not treating logs and logging seriously is really dangerous so how do you address this well one is that you always need to assume that your logs and log files are not secure and that potentially they're going to be open to everybody so you need to make sure that you're never sending any sensitive information to logs so don't send email addresses don't lock passwords just don't do don't look credit card information just don't do that kind of stuff because logs are potentially open and you can't trust that they won't ever be seen by anybody else but your own development team also make sure that as a software development you have a grasp on where log data is sent to and how it's being stored and also make sure they have clear how long that law log data is being saved and when it should be deleted and make sure that it actually happens that it's actually being deleted and for that reason it's actually pretty smart to use a locking surface because they're supposed to be good at that stuff and they're supposed to manage that stuff properly for you even though logging Services can still make mistakes and have data leaks themselves that's why my first point is so important never assume that your log files are secure and simply don't store any sensitive data in logs if you do store things yourself whether that's in a log file or a database just make sure your team treats logs seriously it potentially contains sensitive information that's for internal use only and you want to be careful with that knowing how to set up logging properly is just part of how you can make building and maintaining software products more manageable I did a video a while ago about some other aspects that you should probably think about as well you can watch that next if you'd like thanks for watching take care and see you next week